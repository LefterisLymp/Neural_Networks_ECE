{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "Kaggle_final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3F7ozFwwfN8G"
      },
      "source": [
        "Ομάδα 4\n",
        "\n",
        "Νίκος Χάιδος, AM: 03118096\n",
        "\n",
        "Αργύρης Μανέτας, AM:            03117019\n",
        "\n",
        "Ελευθέριος Λυμπερόπουλος, AM:   03117061"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37MdrTnrRkmP"
      },
      "source": [
        "#Kaggle Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuQyhr5qRkkG"
      },
      "source": [
        "### Επισκόπηση του Dataset\n",
        "\n",
        "Το dataset αναφέρεται σε αστρικά αντικείμενα, και συγκεκριμένα, τα ταξινομεί σε 'Galaxy', 'Star' ή 'Quasar'.\n",
        "Αρχικά από την περιγραφή του, βλέπουμε ότι αρκετά χαρακτηριστικά αποσκοπούν σε οργανωτικά θέματα, όπως Identifiers και γενικά χαρακτηριστικά από την αρχική εικόνα. Εν τέλει καταλήγουμε σε 10 (double) χαρακτηριστικά και ένα label.\n",
        "\n",
        "Εφόσον δεν μάς ενδιαφέρουν συγκεκριμένα τα False positive/negative, αλλά θέλουμε να ξέρουμε συνολικά το πλήθος των αντικειμένων που πετύχαμε, θα χρησιμοποιήσουμε ως μετρική το accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.052014,
          "end_time": "2021-11-18T21:05:47.494001",
          "exception": false,
          "start_time": "2021-11-18T21:05:47.441987",
          "status": "completed"
        },
        "tags": [],
        "id": "93b17638"
      },
      "source": [
        "#### Ως προς το splitting σε train και test dataset, μπορούμε να βάλουμε 70-30, γιατί ήδη έχουμε αρκετά δείγματα (100 χιλιάδες) και μπορούμε να μειώσουμε τον υπολογιστικό φόρτο για το fitting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "papermill": {
          "duration": 0.058622,
          "end_time": "2021-11-18T21:05:47.603288",
          "exception": false,
          "start_time": "2021-11-18T21:05:47.544666",
          "status": "completed"
        },
        "tags": [],
        "id": "8df267e7",
        "execution": {
          "iopub.status.busy": "2021-12-01T12:25:43.705344Z",
          "iopub.execute_input": "2021-12-01T12:25:43.706214Z",
          "iopub.status.idle": "2021-12-01T12:25:43.734661Z",
          "shell.execute_reply.started": "2021-12-01T12:25:43.706102Z",
          "shell.execute_reply": "2021-12-01T12:25:43.733934Z"
        },
        "trusted": true
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=Warning)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "papermill": {
          "duration": 1.64614,
          "end_time": "2021-11-18T21:05:49.300419",
          "exception": false,
          "start_time": "2021-11-18T21:05:47.654279",
          "status": "completed"
        },
        "tags": [],
        "id": "t8C6gCDPXJAs",
        "execution": {
          "iopub.status.busy": "2021-12-01T12:28:28.314695Z",
          "iopub.execute_input": "2021-12-01T12:28:28.315127Z",
          "iopub.status.idle": "2021-12-01T12:28:28.615335Z",
          "shell.execute_reply.started": "2021-12-01T12:28:28.315093Z",
          "shell.execute_reply": "2021-12-01T12:28:28.614167Z"
        },
        "trusted": true,
        "outputId": "b89510a9-ed5f-44fc-b803-00880a1f85f6"
      },
      "source": [
        "import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df = pd.read_csv(\"../input/sloan-digital-sky-survey-dr16/Skyserver_12_30_2019 4_49_58 PM.csv\")\n",
        "df = df.drop(['run', 'rerun', 'camcol', 'field', 'objid', 'specobjid', 'fiberid'], axis = 1)\n",
        "x = df.drop(['class'], axis=1)\n",
        "y = df['class']\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.30)\n",
        "print(f\"Συνολικά, έχουμε {(y_train.value_counts())['GALAXY']} δείγματα από την κλάση GALAXY, {(y_train.value_counts())['STAR']} δείγματα από την κλάση STAR και {(y_train.value_counts())['QSO']} δείγματα από την κλάση QUASAR στο training set.\" )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Συνολικά, έχουμε 36005 δείγματα από την κλάση GALAXY, 26591 δείγματα από την κλάση STAR και 7404 δείγματα από την κλάση QUASAR στο training set.\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "papermill": {
          "duration": 0.063258,
          "end_time": "2021-11-18T21:05:49.415345",
          "exception": false,
          "start_time": "2021-11-18T21:05:49.352087",
          "status": "completed"
        },
        "tags": [],
        "id": "a93ef88e",
        "execution": {
          "iopub.status.busy": "2021-12-01T12:28:30.405209Z",
          "iopub.execute_input": "2021-12-01T12:28:30.406643Z",
          "iopub.status.idle": "2021-12-01T12:28:30.416688Z",
          "shell.execute_reply.started": "2021-12-01T12:28:30.406578Z",
          "shell.execute_reply": "2021-12-01T12:28:30.415469Z"
        },
        "trusted": true,
        "outputId": "960dfe02-63b5-491b-f52e-a2af902ab926"
      },
      "source": [
        "print(\"Επίσης, βλέπουμε ότι δεν χρειάζεται να κάνουμε κάποιο imputing, αφού δεν υπάρχει κανένα χαρακτηριστικό που να έχει missing values στα δεδομένα μας.\")\n",
        "print(x_train.isnull().sum().to_string())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Επίσης, βλέπουμε ότι δεν χρειάζεται να κάνουμε κάποιο imputing, αφού δεν υπάρχει κανένα χαρακτηριστικό που να έχει missing values στα δεδομένα μας.\nra          0\ndec         0\nu           0\ng           0\nr           0\ni           0\nz           0\nredshift    0\nplate       0\nmjd         0\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "papermill": {
          "duration": 0.063533,
          "end_time": "2021-11-18T21:05:49.530189",
          "exception": false,
          "start_time": "2021-11-18T21:05:49.466656",
          "status": "completed"
        },
        "tags": [],
        "id": "d2dfc1e1",
        "execution": {
          "iopub.status.busy": "2021-12-01T12:28:32.120613Z",
          "iopub.execute_input": "2021-12-01T12:28:32.121100Z",
          "iopub.status.idle": "2021-12-01T12:28:32.132092Z",
          "shell.execute_reply.started": "2021-12-01T12:28:32.121051Z",
          "shell.execute_reply": "2021-12-01T12:28:32.130510Z"
        },
        "trusted": true,
        "outputId": "3d1b9eef-b1a0-44b4-8246-12bc760169f8"
      },
      "source": [
        "print(\"Όσο για τα Variances που θα επιλέξουμε για τον VarianceThreshold, κοιτάμε ανά χαρακτηριστικό περίπου τι τιμές έχουμε, για να επιλέξουμε κατάλληλο parameter grid αργότερα\")\n",
        "print(*(x_train.var(axis=0)), sep=\"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Όσο για τα Variances που θα επιλέξουμε για τον VarianceThreshold, κοιτάμε ανά χαρακτηριστικό περίπου τι τιμές έχουμε, για να επιλέξουμε κατάλληλο parameter grid αργότερα\n6078.460421134806\n423.50251061125516\n0.6943034664538194\n0.9732883273265153\n1.2897261257312236\n1.4661682617807696\n1.6490547717757358\n0.19133342885482438\n4884870.209922411\n2390858.3334018434\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.051006,
          "end_time": "2021-11-18T21:05:49.633313",
          "exception": false,
          "start_time": "2021-11-18T21:05:49.582307",
          "status": "completed"
        },
        "tags": [],
        "id": "90d09d63"
      },
      "source": [
        "##### Οι πολύ μεγάλες τιμές στις διακυμάνσεις τεσσάρων χαρακτηριστικών, σημαίνει ότι μπορεί να έχουμε outliers στα δείγματα, γι'αυτό θα χρησιμοποιήσουμε τον RobustScaler."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heBsH0aM8TTP"
      },
      "source": [
        "Θα εξετάσουμε την απόδοση δύο ταξινομητών, ενός Mylti-Layer Perceptron (MLP) και ενός Support Vector Machines (SVM). <br>\n",
        "\n",
        "* O ταξινομητής MLP είναι ένα πλήρως διασυνδενδεμένο δίκτυο με ένα ή περισσότερα στρώματα από nodes μεταξύ της εισόδου και της εξόδου. Κάθε νευρώνας των στρωμάτων έχει Ν weighted εισόδους και μια συνάρτηση ενεργοποίησης.\n",
        "* Ο ταξινομητής SVM έχει στόχο την εύρεση του υπερεπιπέδου που διαχωρίζει όσο καλύτερα μπορεί τις δύο κλάσεις. Στην περίπτωση του linear SVM, αν w είναι ο πίνακας βαρών και το υπερεπίπεδο έχει εξίσωση y = x * w.T + b, τότε αυτός ο στόχος επιτυγχάνεται με το εξής σκεπτικό: <br>\n",
        "![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAO4AAABdCAYAAACisFr5AAAgAElEQVR4nO2dZ1gUVxuGny0UKYoFELB3BIxGxI6iGINdY++IHeIXYyLGxN5j7GKJohJjiyYqKigICKJUAQtYAAFRKVKl7cLOvN8PQBdYioKF5NzXNT929rQ5M88p73lnjoCICAwGo1Yh/NQFYDAY7w4TLoNRC2HCZTBqIUy4DEYthAmXwaiFMOEyGLUQJlwGoxbChMtg1EKYcBllkL6Kxr27D/Eym//URWGUAxMu4y2yKJxeYIYmBm3xRWcjNNVrj5GbbyKV6fezQ8BcHhmFcIjYaoUpvqZYaN0Xupn+OLZhKy481cK44yE4Nakxa+U/I8SfugCMzwRZOK6/noh//pmFliIAsMLQnlqw7PoDXM644fWk6dD61GVkvIE1ooxCxK0xY+mMItEWImo9FIONRSiQSFDw6UrGUADrcRlFqKOeZqlTJEGeVIyO3buj/icpE6M8WI/LKBfu6TV4vRqMRXNNWAv/mcHuB0MxfCpctp5D/RUnMc2Ate+fG0y4DAXwSHBegUNqK3BodmuIKo/A+Mgw4TLKkB28E8uvdsdvu4dBl3W2nyXstjBKkPvgd/x4WA2Lt89AO+Wik9IYPIzO/aTlYpTkX+GAwacH44xTCHTG2GBgs2oM7Ph0BJ9xQojOGNgMbPafGyJmh+7G1NkX0WziKLRVLTzH56fhiXsgGq09jzVmyhUnwPh4UDWQxt6k4xsmUhc9HdLRN6d1oQXlBy64T1ssDEhHx4B6zt5NZ2/FkKQ6mcuXI2Admbc0pjl/pxBXvYRonXlLMp7zN6VUK6HaR8H9nWSpIyIBQCh1KHX6hYIruLWMj0/1e1wuAut7dMaKYB4GM//Bg6MjFHrYZF+bD5OhBxErNMXaUH+sMPqv9WcMRs1R/TmuoAEaaHdCj65qSPh7N/6M4cqG4V/g9MEw6HbWglCggbp1BdXOlsH4L1MDxikBBEIdjLYbC/1cH+zbHwhpqRCy+4dxQjYJMw2VAJQVLZ/5FP5Xz+Pc+asIiM1C8csoMmkucnJykJOTg9xcKTjwyJcUnsuVyPD2pRUpEkM9ERgv12hIXiD4RigSeYDPiMYtVxfcis4qzhFZT2/jirMHwlNLNjTSxFB4Bsaj+CwnVwb5I1eSL5c/j8ynfnA9fwHXguKR865VyPMo/QIOeyGHURE1ZFUWQH3gt5jVSYDHTrtwocR7YFm45uCGNnMnoXGZ3Hikea1EfzNrnHlOoBfnsOBLI4x1jAKHXDy9cRC2vRpDU6M+etn7IFGWjtBNX0G/3Uisv/IYWQCyw52xaUIntDD9Btv9pQAyEHZ2FUYZtUKPqftww30tRvS3wqQpo2BuYgY7l1jc3joKPQdNx7ypg9GlqzXOJvBAdjicN01Apxam+Ga7f2Hjw8dhz1AjDJ6/DCtWrcKqVavwy+x+aFK3LpqOPISnHAAuDheWW2PZqcd4nRmKfZNMYDxqL+5KFNVTDh57HcPK8WZo12osjiRm4M6+yTBqqAaDMcfwjOeR7LUew9troV7HpbhZugVkMIqp9iyZS6R9Q4fQ3pcyen5oGGkJ61DvLQ9JVvx33AEa0W8VhRbk0YXp2iRUtqCdz4otP2l0ZJgaqQzaR4kcEVEqOQ5TI+V+Oyi2KEhB5H4aoi2mxqOPUVxBIp2bO5J+9skoUQSpz/+ojZIWTfgrp+iMhFznGJBYqzstdAqgZBkRl3CSJuiJSN14HG2+9JQkRJQX9DN1VlIhi13PCo1aUh/6Xxsl0prwF+UQEcmiyGH90aKyEZEkjDaba5FYbzQdjZERkYwid1uRxcoQkhYFeX1hBumJ1Kn/jqg3dVASCV1f0Jzq9N1M151+oO8d3OjI9Cak1H4JeQbsooU/HifPzQNIRcWKDqWWjltA99b3oYb16lG9Co4GXZbRLamivBn/FmrQAUMAg4l2mLDBFY6HHOBjtwcWavkIPXwKoqkn0EkMxJWJUw9f/+CA/fgK2sJ8JAZeQeALAgkz8ZoHIATEbebAYZMrus9fhtkzXaFtug5H+9YrkYpQQxPqpcqioaEOgXonDJ9gBm0RAJ1+6N1BhPOi/pgxpCVUAMDYFCZ1eYQkJECGplAWakBTPiFRE0yY+w3qCwEgG7fWzMJavwaY/td+TG8hAmT38afTbSQ3OYTv7QqHE5QZCR65CPLxQ+53rVHabx+yJ7gZkIy2xpm4mT8NG+Y3wtELaajbUQ3BLvWxaP14ZK7aDLT4Gh01SkcWw+iHq4ixk1U4lBaKVKDGVm7+1dSs55TGQNjN7opjK09i91/LYT4qEPs8DDH3mgGEUDR2FEKv3zQMufU7fpgZBFHXEWjXQgWII7w1dYvQYuYubHLujrmXX2PfJiOUeSaFwjJjfqGo1FxaqARlZQEgk09bCUpKgEwme1MeYYmEVNBQWwUAj1TXpbDZ9hCtF7lg2yjdwvzyH+JhtBrMVv2K7YPflmqHIyAUiRVWLvfMDR4RdSA264Tp1p2gmnkCHkFCGPQGmttMQXtRJDbdiIK2uSW+VCA+oYo6NFUUJFwJ48aNg5eX17tHrCJ16tTBo0ePoK6uXnlgRrWpYZdHMTra2GLIdmu47D2Ia6+DEfP1JliW6TmKyUfEgQkYeagZ9l09jEHa+fjbX4HFWZKI5+J2MFa+jjXfn4TVmalo+hF9vvgXZ7Fo3mEkmK6Ex9r+cstdHDhZGqIiX0E0vGUVHDZ4JLu7I5SaY8nsMWglAnJ9PXA7W4wOlpMxpqkQfLw7PO5pou+S3lBVED/h+l44eCRAge3+DcKGvTFn8TC0kCuQk5MTcnM/nPeTsrIyE+1HpMZ9lYWNx+Lbyetwad8uTEuzwLZbRuVnkuuKLStdUM/uDiy05ZRYYmk5HdfXO4D77hIujrRBj9k/YJFTH5yzbvFxPJu4aByevwh/5Q3EriPLYKoGABzi7kVAs0NbtG/B49JRB9ye8xv6Fo+LJQHY4ZCGeUusoFYisUx4uAUAfdbBposygHwEXfdBSsMhWDijA8QAUj2vI1jcCzv7lRlkFyIUQSQWK7DNywcRlvlfTU0NampqCsMzah/VFy5lIzsnB3xOsdjUYG47B90df0aClS3G6RULUoacbAmIcpCdXRSWy0JWHoe4O/54LuuI+hFncCk0D6A8ZGfGI16oB+H1n3Ck/g842lcLKr13YOM/pphrbwdH84uY27pIujIeHDjwchM/nuMBkltm4QlEBPC83FCZQAQQ92YBCjwHcG8SkuLeNhvYX1PGN8d+x/z2RdXFJ8Prqj8GGM/ClBk9sMd+FyaMEGDT6mkwVYvDtV2HkGRzCmVkkuMN91sF6PHLCDQRApCFw8M7Hnqj92NYfQCQwM87ANIuS9DKezdOGy3EREP5WySE3gBbrBnwHvepiL1798LOzg4PHjxASkoK+vfv/85pxMfHIzQ0FCNGjMDZs2dhbm4OXV3d9y8U492pjmVLGuNLZ3bbUGcNdepss4fO+MYUWle5ZDo5fQRtDi+0q3IJweR8+Efqry0kCOqQycxddPpmNEm4JDo/uy2pCpSonoEhWSw6Tqe+60BioRaZTN9PF5zmU7cGevT1Jt9Cy252BJ22NiQlCKluF2va6RFLklgfclxoShoCMbUYs4Wc7ydQpOc+sjZWIYFSe5qyy5nuJsWSr9PPNKixiIQ6A2jZsZsUkxhGF7ZNonZKAqrTaRY5uPnQdceFZKohIHGLMbTF+T4lB64mUzUBifX70PSFtmRra0u2tvPJesQXpD/kd0ohIiqIptPzupCWSEAASKBsQIO3+NFrBfUlcV9AzdUtaGdMoZlaFrWV+tRpRvPc8goDcC9p70AVEjXuSYtOPaaaNgwXFBSQSCQiIqK9e/fSwoUL3yudixcv0vDhw4mIaMiQIXT58uUaKyOjalR/Oai6cOkUecuL/CLTqICI6HUk3fZ5QCmK11I+U2SUHnmbrl5xp8C47GqllBUVQP7Rr6vnc10OTLj/Hj79+7hCLbTp1R9tin9rtkHPvp+yQO+DCFptemJwm8pDVoZGazN0r34yjH857H1cBqMWwoTLYNRCmHAZjFoIEy6jAnhwXMnfjM8DJtz/PDnw22ODEX2N0KTNbFySc67KvmGP6ZvvQQYAXAz2WDZCq/muyPtURWW8gQn3P08dmExYiQ2zTID4YAQ9LvLbzr+LHfYHcOtFcqF7pagZRi0ciXqvXlXobsn4ODDh/ucRQkOnOUzGjUZvtWeIis4HwCHmz6PwyRchLflVYY8LEXR022HouMFlPcIYHx0mXEYhys3RvLEUSYkZ4JKdcSTOAosH6EKWmlS4Py4Xi3OeWhg/Rpc9NJ8B7B4wChHpQKchkJn2HN6HgmA41wrtG2sDKclI4nm8dLmI/OHW6MTe8/0sYMJlFCKqD626QOad/bjcYBrGGyhDR7cRRKnJSIx2xrmsQZjSueyLhoxPAxMuowgVaKiL8DxOH+OtDSEGoKyjjXrpAXA8mYevx3cs+wEDxieDCZdRhBAq6u0wY9OP6FHUsYp09aDXsjtmLpiAdp/eq50hB7sdjCJUMfpYMEbLnRF3WYugiE9VHkZFsB6XwaiFMOEyGLUQJlwGoxbChMtg1EKYcP9DCAQCCIs+HC0QCCAQvN/ma/Jxq5MO4/35V2xszag6gYGBMDMzQ2pqKjIzM9GqVat3TkMikSAyMhImJiZ4+PAhmjZtCg2Ncj+ezfgAMOEyGLUQNlRmMGohTLgMRi2ECZfBqIUw4TIYtRAmXAajFsKEy2DUQphwGYxaCHutj6GY3GtYY+uJ+n3UcOv3e+hgNxIa3tcgW+CEn7qyx+ZTw+4AQyGyuDoYuHETeqSsw5kz5vh1ynRotWiCR8bskfkcYJ5TjArgELP9K0zN3gXvlcaslf+MqPYcV/roBBYMNMc3izdj5/Y1sB1jjl4WA2E6ZAPCZVVLg4vzxoH53VBPpIIBu+LL3+giPxDr+rWC8eyzSPqv7YaRFQqnDdtx5an04+XJp+D6jQz0smz3YUTLp+K+6xHYdlODckd7+OeX+jvNHwd/WoOzURVcM5+JZzHF335+Fzi8Cj6BX8Z+AZ22dvCspFpzrn+H3lNPVPrc8c8OYnRve/hKSp7Pz8l9jzJWQLV215X40fIvGtOQg3FyGzFnUeAGc2rUbS09KKh6UtzLPTRAWZksdj77IJs6l4+E/I+foLuVlFXif5xOVBboQyENp33jx9O28Jreo74S0k/RBOM55JL3AfOQRdGvvVWp6Tw3UpQNl3yJFn5lQ2efl/NUyMJpS19davuVLe12f0o5VcyWSwoml4unaHG3OiRusZA8JJVEKAillT370aaIinZcL6DQld2p55p7JP+kFIStoa6qmjTIIbaKpaucavW4+WEXcOGhOtq0byzXdWug2/erMa2l6J3SEqrWgeoneDuMjz+FrftD8LqilpSPx6mt+xFSYaAPRT7ubpsPh3ozMafjx/3OYs5Nd9w3Hohe7/pVVtkjnN95GmGSyoPySe64flcDfSx7QFE2Qu0hWD42CcvtjiFO0d4noo5YetUP+4YRnOebol3P6Vh/7j7SK7lVQp2usBoxGkO76aBKj524E+bOqodzB24it7wwOV44eEEH1jZGJUYoYhNbHHW5jD1TmlclpypRLeEKVVWgQjE4uWYr/ORrSrU7LM0bQSgAwEmRm5uDnJxcSGSFYfh8CXJzcpCTK0F+cTT52stPRJi7My77RiGz1A3IT74Hz4Bnpfav4ZH51A+u5y/gWlA8csqUNBfxd67j4vkruBWd+WYoziX7YP2MH+GcnI/83BzkShU8GVwyfNbPwI/OycjPz0VOrrRE3vmJ93Hj8kVc8YnAq/cdC1XwkPGJZ7B2Vyx6jraA5nsmX2n2XOnaBLJiveGwzwUFdWR4mfaOuwXJHuDs5uMIrsLuYBkebggU9ICluToAHnyZuhDCYNQYdLixAVu8yt5ZAIBaS1h+6wD3iAc4O1cPd1YPQLtOo/DjYV+8qHAILICSuKqTACEMJi6Aqc9yzLf/CT/9VPawn78CPqazMd6glKyEDWFiYY729aqYVZVKUw3ExpMwo29dpHmtgGW3UVjtHFXUGqlhiO1cGIoAPvkB3A7MhImWFvpsCIcMPDIjPeE4ryvqa5liVXDJiY3sxT+Y17cvRs2YitHmRjAatg1B2QAkj+Dy21R82aILRm69hTf3g4vDheXWWHbqMV5nhmLfJBMYj9qLu0WtPZ9wDSvHTccO/zTIUlzxvZkhBm30QxafBv/zrghPl4JPC8CRtauw9o+gUqLnkeZ/Hq7h6ZDyaQg4shar1v6BoBwAfBI8Vo/BiGWX8CwnDSEO42DU8RvsDs5WXFnSQOybPQrmJk2gO2AbnhRpgXu8Df0atcF8lywFkXjE/3UUV3NNYd6zdH/E4fGpJfimnzGa6A/AtggOQAb8fh2K5hqNMfF0aonQOX57YDOiL4yatMHsklvywX76Ztwr3JIPMXss0ajVfPg26oelrgl4cmQKDBu82+ip6mTjhpsvpF16QPv8XJjpq0NZ3QB9f7yCBHkBNzBDtzbPcdbxCjIqSk5ZDz2tt+D83cfwWPklXv4+HsYdBmDuds+aKa6GJWzHcPAK4dGkeXM0lz+aihHhm4cRc79GsT755FA4H/gBI7u0Rsf5l8vvqd+H6o61uSQPWj2oCSkLQBCoU2urZXQmPKtkoJxTNFZDibqufjv2z3OeSbpKRrQsoGjeln6YhqiIyGD4TgpI44i4VPJZ1ZcaCFXoy5UhhWGk/mTfUYk0vjlZNJeRUeRuK7JYGULFs7/XF2aQnkid+u+IIpkskvYObkFW+4vn4CnkOEyNBOoj6FgaEZGEXGYbkFK7xXSzgumjxGU2GSi1o8VvAnH03Gk06bf/jnyKJ2ayKNr7lRYptZxNl1IVpZJNyc+iyMO+K6moj6Rj6cUFvk3bh7enwTvjFMRJpaPD1Umpw4/kp6B8kvQXFHlzN402UKLWi7zo6cmFNNZuLa3832I6EFRytsdlJVHsvSM0wUCZvlgRUnQfpBS21ow0mi8g96I5nuzZ3zSz8xhySi+d2zuQd5Ym6Q6hQ2mVhXOjeU2VSNtsItnvuUIhEYF03MaQlJU6kr2//AVn0YkxmiTSt6ErVZ5vF1CC3z6aaqhGovqTywkjJe9FrUmpKnPcIriXR2n0F7PpckbJ85JbP1BXyx0UVXoKnOpIQ9W0aPTxyirj3ai2VVmoMwCrrt6F7yFbmOvL8NR1MyaadcWk3+/LtTAClPm6iVCoYG4hQruBY2BaXwgIG6Dv8m2Y15HH/UsXiv7WhIa6XHBZBP50uo3ku4fwvZ0d7OzssOxcJHjkIsjHDxl3HLH/ZjNYft2kaGjREOM2OGHP7iX4qjrDFlk4HHe7oKB7f3Qr7ghFrTHFZjDqxp3C3rMvFURSh3bT1ugzvB+acwl4kVDU5WqaYejgkbAaZFA2Sv5jhD+RAg11oKOg01PR0kebPvOwdHJrPL+8GqujhuPArhVYs3M75pmW3FNPqKGD5ibjMLq3Gp5FRSMfABfzJ4765EOUlvxmmC/S0UW7oeMwuO471Ed2DIJ9vOHtXXT4PkFKQQae3pY75+OPJ6Umnvl3rsIrURsDv9+BjXZD0MWwGyZ+Ow5GeIm4ePl5hxJ0dRsArx4j4mVlw/ZcxHo44NvBhjAccQC5Ix3gG3H0HS6mYoR642DbJxC7/4iRmzKl4qKDK9raTEPrUvdJEuiPMIEpBlrU4DgZNeWAIWyAbjZ74T12Lk6s/R+W7vHGmW8no4VJMDb1VHn/dJVN0K2zJsjzRXFGEMk3NfkP8TBaDWarfsX2wW8NNzscAaFIjKxjwxHF1YG6+ttImp3GwrbT+xcJAJAZgIBwGdR7aJZofDQ7d0E70Tk8uvcQgL7CqCJ9feggFUnJHGAoAv/yHI6lWGJpRwXKpHSkZxEE+spQKteCoozOA82hs/sOWo+2RMMKm2JlNG/eGNI7icjgkhFwJA4WiwfAdWwIklJ5QJ0Qe84TWuPtofsOTToXfxU7ljshulhrlIGnWcmIWW0Pz+LLEjbGmJ1/YalZ8X2SIcLNE3HNxuL3UW+Nm3yeBBJhYzQ1kH80BaijpgoBMpGRRoCir+3wmXh46QC2bt2LC89aYrTtb7j913AY1qtpr1519F84Easn78HtOdvRVxXgov7AwQcDscKxYamw+bjj7o0045kY2Lhmy1Gt1LjoP3DIVW5WWK8Tpmy7CrctFqgne4QL50OrWz4oK6tAoF6eWYYDJ0tDVOQriJSVoSx3iIsVzsXgyZP8cuK/JzwHGREyUlNLrM2J6mtBUyiAimr5ZliRtg4aiVKRnCwD+CRcPhyJvnYDoaUwtAqUxQBJ8iCtwE0mV0pQEUYhLFTRPLlE7tAp3JIPz70PIchwLqzaN4Y2UpCcxIN/6YKL+cNh/Y5b8okMF+CErz/8/YsO7/WwbNAT9m5y525fkBMtAO4p3K4/gvYAK3R/07bzSAgMQnyzwRj2Zcky8DwPQAWqaqVbsGyEn12F8abtYb7MF1rT/kTYEx842o/8AKItut4ONpjX9gp2nEkADykCDv4B6YS56Fv6tssews3zGVr2H4hWNWwmqN6V5b+ExzV/lLT6q8Bo1gz0U337RUEIxVASF1e+PIQK/bb4dDyLz0TDHuaK/1dui/YteAQcdcBt+WdWEoAd21whaN8ezRCN8394IlPu7zSXHThwpxrL4fW64Ms2QmSH+CNMrk3gsrKQi0bo0beCLl1JG9paErxKzkD8hYN41NsWVuV1k+IWaNlUCHqdgbTy6inzBo486IrJXaUI8g0sNNqVa6UWoX7hlnzYf7kBpo03gLKObmFDkhgN53NZGDSls8JlmZqGT3SH+9266P91n7f5Se/gsNND9P1+EXqXGKgRXr/OAak2QXP9UgqQxeHGtTgY21/FoweXsH1ePzT70Bcg1MFYOys82XsAd5MuYq9zc8yyNkRpbXKxbvB4rANzyy9qfMO0ajZJHGJPb8TeuyVtsZJHEYgWmWDsN52LctGHgS4QGxKEBA6QJXjh4IlAZFEOXmfLP5GE/Px8FJ+RPT6Bvx71wFL74YqzF3fBlBk9oBKxCxNG/Agn73sID7qE7bM3IPFLc2j1mIapnVUQe3Qupqw7j4AHYfByWorpRwnmnQuHYqoqSkBaIhLyZEh4EK7YM0ZVBUpIQ2JCHmQJDxCe3gVz7Aah7tMz2HcxqUgnPFJv+SHGZC7srCpYuBFpQ7chkBzsgIPPB2HhwPpv/+MzEHbFHY+KjQOipujVvSUEL2IQV2LQkINH7pdwJzke5391Q7MZM2HVqyVe+fngXuINHHAKQC4APiMMV9wflbBmqmioQ/Q8DvrjrWFYuCUftOulI8DxJPK+Ho+PtVScft0dQUp9MLh/8dchM3B744+4ZLgN++a0KikCPgPPnqVCZNwdZqWrVmwE28PHsHJCZzR8516NwHEcwHEllvj43HSk5VS8EKzaZwFmqv+JpTbbccd8LsbplZYSj+Tr1xGm1gsWLW9g/4m7qNFxX3UsW7KIjTSoQ1fq0qkXjVvyGzmePE1O2/9HX3/Zi+adeERv7YIFdG+7BTUUiUlTryUZWa0i1+PW1FikSm3HrKZzdzOIpPfoiE1vMmjYgUYv202H96+kqUMn01bflLeeVLKHtLG7EmmMPfXWQ6Ygmk7P60JaIgEBIIGyAQ3e4kevi/6WRDjS1A4aJAQIAjE16raQTkcV27Y5Sj43jQzEItLUM6ZRO8NIkXGRSz5H0wzEJNLUI+NROylMQkRcArn8ZE4Gej1o3rZjdGznYhozbCGdeFyJdxP3nHZbqJKOlQNFlA7KpVGIsyuFyxmEpf5LqaPqF/RLiJwvjsSDbFuISVWvN/1wJZE4IpJ4f0dtlbSo44TdFPi6OLkQcnYNL+FNlPfPDOo6z4XeGI0LQmiFqSHZnE+oOY+1Sq3KHKXd3k4TeluQ9dqDdNxpD/08ezxZr7lMsYqqT+JJti01yfy3x1TGb6kglFaZapCKikq5h6rWOAVpRpP3qZ003UiFBModaPK2k+QTIyXKuUQ2BmISapnSL95ZZePJXUPK6Qmko9yJfg5SVGgp3VrSnpRUW9NXS47T/aq6dFWR6i0HZcVSTCJHRFJKeexPHi6X6IpXKD3LVhRYSglhnuTm+5jSOSIu8S753kui0pcsSYmiYK+r5Hb7MaWV9jCUPaSN3ZVJe/qFUu5xMkqPvE1Xr7hTYJyCzKVJ9MD7KnkEPqX0sneekh/cJO/7SVSRQ2NB8gO66X2fkkoFynkeSl5Xr5J32HNSeNllEnpI222+o8tJpWQiS6H7f2+jlcdCS5aDi6PDw/Wp9+ZHcg8tR6nhN8n/qXyO2fQ0KJSeFy/rpNynv7etpGOhJQvMJT6mx6nyeefQ00exChusD44sg6L93enqjRCKzSjflbAgaDl90XIWOdfsiko55FFsgAd5Oc6iwT/5l3k+3wUuNZx8bkVSxgfw4a32Ou5HRfaA1pqqU88SD3EtQvaMnFfb09Fwhf06vXQYQcP3vSjT88kif6dRvW3JLUNBtPLgXpLDiOG078XH9fyuedLIeY45zTpXgyOCSski359G0aKrrysP+on4/L+Awb+A18Ht+CMgFbzsFVKEX2H2xDZlDAGfLzI8+N0aYxZtxrp5q/DQchlmdlS0RJYJz5sF6D1At4zhQdTGBo4b9XF63d+K/XUVkemJmwW9MeBd1nU+OzjEnd8Gjy47sfubxh/ncy2ScPyzdSu8O63HxsEfysm0BvjULUelFITRnrFdqW2H/jTr51/peGDaR357qLq8JtclvehLywV0OKSCLjP7PM0a8DP5ZZc/YM+LdKGjZ4IptQoVkH1+Fg342Y8qSO4zh6MXfmfotPezCqcw/1XYi/SfCfn+9ui5JAeLty7H5F761V2ng799TyzJWYytyyejl35t7nUZimDC/VzgMpGUKgVC/OkAAABSSURBVIaujnrlYauUXBJSxbqooeQYnxlMuAxGLYSNoRiMWggTLoNRC2HCZTBqIUy4DEYthAmXwaiFMOEyGLUQJlwGoxbChMtg1EKYcBmMWsj/AQSerPhcoGqdAAAAAElFTkSuQmCC) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvxnP-iq4f9n"
      },
      "source": [
        "<h2>Out-of-box metrics</h2>\n",
        "Παρακάτω βλέπουμε τα out-of-box accuracies του MLP."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "papermill": {
          "duration": 45.268239,
          "end_time": "2021-11-18T21:06:34.952881",
          "exception": false,
          "start_time": "2021-11-18T21:05:49.684642",
          "status": "completed"
        },
        "tags": [],
        "id": "c2706c12",
        "execution": {
          "iopub.status.busy": "2021-12-01T12:28:33.822247Z",
          "iopub.execute_input": "2021-12-01T12:28:33.822721Z",
          "iopub.status.idle": "2021-12-01T12:29:13.368685Z",
          "shell.execute_reply.started": "2021-12-01T12:28:33.822679Z",
          "shell.execute_reply": "2021-12-01T12:29:13.367841Z"
        },
        "trusted": true,
        "outputId": "3b08310a-3431-41b3-f591-e7c4fe1cdcf3"
      },
      "source": [
        "import sklearn\n",
        "import time\n",
        "from sklearn.neural_network import MLPClassifier as MLP\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "x_train = x_train.to_numpy()\n",
        "y_train = y_train.to_numpy()\n",
        "x_test = x_test.to_numpy()\n",
        "y_test = y_test.to_numpy()\n",
        "\n",
        "estimator = MLP()\n",
        "estimator.fit(x_train, y_train)\n",
        "pred_ootb_MLP = estimator.predict(x_test)\n",
        "print(f'Οι επιδοσεις για τον Out-of-the-Box MLP είναι:\\n')\n",
        "print(sklearn.metrics.classification_report(y_test, pred_ootb_MLP))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Οι επιδοσεις για τον Out-of-the-Box MLP είναι:\n\n              precision    recall  f1-score   support\n\n      GALAXY       0.56      1.00      0.72     15318\n         QSO       0.75      0.67      0.71      3177\n        STAR       1.00      0.00      0.00     11505\n\n    accuracy                           0.58     30000\n   macro avg       0.77      0.56      0.48     30000\nweighted avg       0.75      0.58      0.44     30000\n\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSavV7HplvCh"
      },
      "source": [
        "Παρακάτω βλέπουμε τα out-of-the-box accuracies του SVM για διάφορους kernels. Επειδή όμως τα δείγματα του train dataset είναι της τάξης μεγέθους του $10^4$, δεν είναι πρακτικό να χρησιμοποιηθεί η υλοποίηση του απλού SVC της scikit-learn χωρίς preprocessing, διότι αυτή η υλοποίηση αυξάνει το χρόνο του fit τετραγωνικά με τα δείγματα. Για αυτό, θα κάνουμε πρώτα **stratified sampling** στο dataset έτσι ώστε να μειώσουμε τα δείγματα, διατηρώντας τα ποσοστά εμφάνισης των κλάσεων. Για το stratified sampling θα χρησιμοποιήσουμε τη συνάρτηση StratifiedShuffleSplit. Έπειτα από δοκιμές διαπιστώσαμε ότι για να έχουμε έναν ικανοποιητικό χρόνο εκτέλεσης του fit, θα χρησιμοποιήσουμε 500 δείγματα στο train set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-03T15:22:49.749715Z",
          "iopub.status.busy": "2021-12-03T15:22:49.742760Z",
          "iopub.status.idle": "2021-12-03T15:23:00.683081Z",
          "shell.execute_reply": "2021-12-03T15:23:00.682349Z",
          "shell.execute_reply.started": "2021-12-03T11:23:57.637739Z"
        },
        "papermill": {
          "duration": 11.011219,
          "end_time": "2021-12-03T15:23:00.683227",
          "exception": false,
          "start_time": "2021-12-03T15:22:49.672008",
          "status": "completed"
        },
        "tags": [],
        "id": "2733c122",
        "outputId": "205c3062-3bf6-4970-9d3c-71055a8b58ef"
      },
      "source": [
        "%%time\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from tqdm import tqdm\n",
        "\n",
        "from IPython.display import Markdown, display\n",
        "def printmd(string):\n",
        "    display(Markdown(string))\n",
        "    return\n",
        "    \n",
        "x = np.array(x)\n",
        "y = np.array(y)\n",
        "sss = StratifiedShuffleSplit(n_splits=1, train_size=0.005, random_state=0)\n",
        "train_index, test_index = next(sss.split(np.zeros(x.shape[0]), y))\n",
        "\n",
        "x_train, x_test = x[train_index], x[test_index]\n",
        "\n",
        "y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "acc_d = dict()\n",
        "kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
        "for kernel in tqdm(kernels):\n",
        "    svm = SVC(kernel=kernel)\n",
        "    svm.fit(x_train, y_train)\n",
        "    preds = svm.predict(x_test)\n",
        "    acc = accuracy_score(preds, y_test)\n",
        "    acc_d[kernel] = acc\n",
        "    \n",
        "print(\"Accuracy:\")\n",
        "for i, k in acc_d.items():\n",
        "    print(\"Kernel:\", i, \" =\", str(k))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:10<00:00,  2.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy:\n",
            "Kernel: linear  = 0.6675778894472362\n",
            "Kernel: poly  = 0.5817688442211055\n",
            "Kernel: rbf  = 0.5687839195979899\n",
            "Kernel: sigmoid  = 0.5132261306532663\n",
            "CPU times: user 10.9 s, sys: 5.96 ms, total: 10.9 s\n",
            "Wall time: 10.9 s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwLdhERZ3ERi"
      },
      "source": [
        "Βλέπουμε ότι ο πυρήνας που δίνει το μεγαλύτερο accuracy είναι ο linear, αφού δοκιμάσαμε πολλές φορές με διαφορετικά υποσύνολα του dataset. Επειδή όμως αλλάζει και το accuracy ανάλογα με το υποσύνολο του dataset, οπότε δεν θα έχουμε αξιόπιστα αποτελέσματα, θα δοκιμάσουμε μια άλλη υλοποίηση του scikit learn, την LinearSVC, η οποία είναι ένα SVM με γραμμικό kernel. Αυτή η υλοποίηση εκτελεί το fit σε γραμμικό χρόνο ανάλογα με τα δείγματα και κλιμακώνει καλύτερα με μεγάλο πλήθος δειγμάτων. Έτσι, μπορεί να κάνει fit το 70% του dataset που είχαμε χωρίσει στην αρχή σε επιτρεπτό χρόνο."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Om46tC3azwNt",
        "execution": {
          "iopub.status.busy": "2021-12-01T12:29:13.370622Z",
          "iopub.execute_input": "2021-12-01T12:29:13.370930Z",
          "iopub.status.idle": "2021-12-01T12:30:02.892056Z",
          "shell.execute_reply.started": "2021-12-01T12:29:13.370893Z",
          "shell.execute_reply": "2021-12-01T12:30:02.891151Z"
        },
        "trusted": true,
        "outputId": "1f847cb9-2f3b-425f-f321-9218939f9539"
      },
      "source": [
        "%%time\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "\n",
        "from IPython.display import Markdown, display\n",
        "def printmd(string):\n",
        "    display(Markdown(string))\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.30)\n",
        "x_train = x_train.to_numpy()\n",
        "y_train = y_train.to_numpy()\n",
        "x_test = x_test.to_numpy()\n",
        "y_test = y_test.to_numpy()\n",
        "\n",
        "svm = LinearSVC()\n",
        "svm.fit(x_train, y_train)\n",
        "pred_ootb_SVM = svm.predict(x_test)\n",
        "acc = accuracy_score(pred_ootb_SVM, y_test)\n",
        "markdown = \"\"\"\n",
        "{} | {}\"\"\".format(\"Linear SVC\", acc)\n",
        "\n",
        "\n",
        "print(\"Οι επιδόσεις για τον out-of-the-Box linear SVC είναι:\")\n",
        "print(sklearn.metrics.classification_report(y_test, pred_ootb_SVM))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Οι επιδόσεις για τον out-of-the-Box linear SVC είναι:\n              precision    recall  f1-score   support\n\n      GALAXY       0.00      0.00      0.00     15318\n         QSO       0.00      0.00      0.00      3177\n        STAR       0.38      1.00      0.55     11505\n\n    accuracy                           0.38     30000\n   macro avg       0.13      0.33      0.18     30000\nweighted avg       0.15      0.38      0.21     30000\n\nCPU times: user 49.5 s, sys: 239 ms, total: 49.8 s\nWall time: 49.5 s\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvNuIj6XzwNt",
        "execution": {
          "iopub.status.busy": "2021-12-01T12:30:02.893257Z",
          "iopub.execute_input": "2021-12-01T12:30:02.893578Z",
          "iopub.status.idle": "2021-12-01T12:30:03.313865Z",
          "shell.execute_reply.started": "2021-12-01T12:30:02.893544Z",
          "shell.execute_reply": "2021-12-01T12:30:03.313102Z"
        },
        "trusted": true,
        "outputId": "cea7e497-ee42-4b55-d1a1-81ed17b65c0f"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "markdown = \"\"\"Out-of-the-box-classifiers  | accuracy | f1-score\n",
        "------------- | ------------- | ------------\"\"\"\n",
        "classifierss = ['MLP', 'LinearSVC']\n",
        "predicts = [pred_ootb_MLP, pred_ootb_SVM]\n",
        "y1= []\n",
        "\n",
        "for i in range(2):\n",
        "    acc = accuracy_score(predicts[i], y_test)\n",
        "    y1.append(acc)\n",
        "    f1 = f1_score(predicts[i], y_test, average = 'macro')\n",
        "    y1.append(f1)\n",
        "    markdown += \"\"\"\n",
        "     {} | {} | {}\"\"\".format(classifierss[i], round(acc,3), round(f1,3))\n",
        "printmd(markdown)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.Markdown object>",
            "text/markdown": "Out-of-the-box-classifiers  | accuracy | f1-score\n------------- | ------------- | ------------\n     MLP | 0.581 | 0.477\n     LinearSVC | 0.384 | 0.185"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Y4vIpJmzwNt",
        "execution": {
          "iopub.status.busy": "2021-12-01T12:30:03.315868Z",
          "iopub.execute_input": "2021-12-01T12:30:03.317560Z",
          "iopub.status.idle": "2021-12-01T12:30:03.644232Z",
          "shell.execute_reply.started": "2021-12-01T12:30:03.317514Z",
          "shell.execute_reply": "2021-12-01T12:30:03.643252Z"
        },
        "trusted": true,
        "outputId": "bcb23a1a-84b8-4121-883a-5717de221f0e"
      },
      "source": [
        "x1 = ['MLP-accuracy', 'SVM-accuracy', 'MLP-f1', 'SVM-f1']\n",
        "from matplotlib.pyplot import figure\n",
        "\n",
        "figure(figsize=(8, 6), dpi=80)\n",
        "plt.bar(x1, y1, label=\"Blue Bar\", color='b')\n",
        "\n",
        "plt.plot()\n",
        "\n",
        "plt.xlabel(\"Classifier\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Accuracy comparison\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "#to-do: change title"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 640x480 with 1 Axes>",
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9q3rSCIp4zOd"
      },
      "source": [
        "Παρατηρούμε ότι ο MLP παρουσιάζει μεγαλύτερο accuracy και f1-score από την LinearSVC. Ωστόσο και ο MLP δεν ξεπερνάει το 70% accuracy. O LinearSVC συγκεκριμένα επίσης παρουσιάζει πολύ κακό f1-score."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-fc1uTD00l5"
      },
      "source": [
        "#####Βελτιστοποίηση MLP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.053302,
          "end_time": "2021-11-18T21:06:35.059170",
          "exception": false,
          "start_time": "2021-11-18T21:06:35.005868",
          "status": "completed"
        },
        "tags": [],
        "id": "e2bddf0a"
      },
      "source": [
        "###### Για την επιλογή του Pipe:\n",
        "1. Θα βάλουμε Oversampling με τεχνική SMOTE(επειδή βλέπουμε ότι η κλάση Galaxy είναι περίπου 5 φορές μεγαλύτερη από την κλάση Quasar, άρα με RandomOversampling είναι πιθανό να είχαμε μεγάλη επανάληψη της πληροφορίας)\n",
        "2. Variance Threshold, όπου τις τιμές του threshold θα τις πάρουμε από τις τιμές που βρήκαμε παραπάνω\n",
        "3. RobustScaler, επειδή βλέπουμε ότι κάποια χαρακτηριστικά έχουν πολύ μεγάλες διακυμάνσεις ($>10^6$), άρα πιθανότατα θα έχουμε και outliers.\n",
        "4. PCA, για μείωση της διαστατικότητας (αν χρειαστεί εν τέλει)\n",
        "5. MLP Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "papermill": {
          "duration": 0.320383,
          "end_time": "2021-11-18T21:06:35.432214",
          "exception": false,
          "start_time": "2021-11-18T21:06:35.111831",
          "status": "completed"
        },
        "tags": [],
        "id": "596fa862",
        "execution": {
          "iopub.status.busy": "2021-12-01T12:30:03.645331Z",
          "iopub.execute_input": "2021-12-01T12:30:03.645563Z",
          "iopub.status.idle": "2021-12-01T12:30:03.924035Z",
          "shell.execute_reply.started": "2021-12-01T12:30:03.645536Z",
          "shell.execute_reply": "2021-12-01T12:30:03.923297Z"
        },
        "trusted": true
      },
      "source": [
        "from imblearn.pipeline import Pipeline\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# αρχικοποιούμε τον εκτιμητή (ταξινομητής) και τους μετασχηματιστές χωρίς τις υπερ-παραμέτρους που θέλουμε να βελτιστοποιήσουμε\n",
        "mlp = MLP(solver=\"adam\")\n",
        "selector = VarianceThreshold()\n",
        "sampler = SMOTE(n_jobs=-1)\n",
        "scaler = RobustScaler()\n",
        "pca = PCA()\n",
        "pipe = Pipeline(steps=[('sampler', sampler), ('selector', selector), ('scaler', scaler), ('pca', pca), ('MLP', mlp)], memory = 'tmp')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUdJqvOA1Bq7"
      },
      "source": [
        "###### Θα χρησιμοποιήσω μόνο τον Adam Solver, διότι στην γενική περίπτωση έχει το καλύτερο performance για μεγάλα datasets (με χιλιάδες δείγματα, όπως το δικό μας dataset). Άρα δεν χρειάζεται να ελέγξω και τα υπόλοιπα Solvers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-18T21:06:35.654975Z",
          "iopub.status.busy": "2021-11-18T21:06:35.646702Z",
          "iopub.status.idle": "2021-11-18T22:21:54.900752Z",
          "shell.execute_reply": "2021-11-18T22:21:54.902056Z",
          "shell.execute_reply.started": "2021-11-18T19:23:07.891191Z"
        },
        "papermill": {
          "duration": 4519.313187,
          "end_time": "2021-11-18T22:21:54.902703",
          "exception": false,
          "start_time": "2021-11-18T21:06:35.589516",
          "status": "completed"
        },
        "tags": [],
        "id": "Bitgkg2gAUrD",
        "outputId": "6ef243a1-0381-4d6b-e980-184e32afd1c6"
      },
      "source": [
        "from optuna.study import create_study\n",
        "import optuna\n",
        "\n",
        "optuna.logging.set_verbosity(optuna.logging.ERROR)\n",
        "\n",
        "\n",
        "def objective(trial):\n",
        "    pipe = Pipeline(steps=[('sampler', SMOTE(n_jobs=-1)),\n",
        "                           ('selector', VarianceThreshold(threshold = trial.suggest_float(\"Variance_threshold\", low=0.5, high=2.0, step=0.2))),\n",
        "                           ('scaler', RobustScaler()),\n",
        "                           ('pca', PCA(n_components=trial.suggest_int(\"PCA_components\", 1, 10))),\n",
        "                           ('MLP', MLP(solver=\"adam\", activation=trial.suggest_categorical(\"activation\", ['logistic', 'relu', 'tanh']), alpha=trial.suggest_loguniform(\"Alpha\", 0.001, 0.1),  hidden_layer_sizes=trial.suggest_categorical(\"Hidden_layers_size\", [(15,), (12, 10), (12, 6)])))],\n",
        "                    memory = 'tmp')\n",
        "    scores = cross_val_score(pipe, x_train, y_train, scoring=\"accuracy\", cv=3, n_jobs=-1, error_score=0.0)\n",
        "    return (sum(scores)/len(scores))\n",
        "\n",
        "\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "start = time.time()\n",
        "study.optimize(objective, n_jobs=-1, n_trials=100)\n",
        "end = time.time()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.61s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.61s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.59s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.62s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.65s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.66s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.65s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.65s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.66s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.60s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.70s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.61s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.60s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.67s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.66s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.66s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.59s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.59s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.58s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.59s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.56s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.62s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.59s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.55s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.63s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.64s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.65s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.63s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.64s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.63s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.63s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.60s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.60s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.61s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.65s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.58s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.61s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.63s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.58s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.58s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.64s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.64s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.66s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.64s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.64s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.70s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.64s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.59s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.58s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.59s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.63s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.60s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.58s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.60s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.62s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.64s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.62s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.61s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.61s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.63s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.88s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.63s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.70s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.64s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.64s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.64s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.69s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.63s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.63s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.59s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.62s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.63s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.64s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.65s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.74s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.60s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.64s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.60s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.64s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.64s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.64s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.67s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.65s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.66s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.66s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.66s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.67s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.65s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.67s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.70s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-18T22:21:55.046474Z",
          "iopub.status.busy": "2021-11-18T22:21:55.045683Z",
          "iopub.status.idle": "2021-11-18T22:21:55.056381Z",
          "shell.execute_reply": "2021-11-18T22:21:55.055702Z",
          "shell.execute_reply.started": "2021-11-18T20:54:26.913141Z"
        },
        "papermill": {
          "duration": 0.092205,
          "end_time": "2021-11-18T22:21:55.056528",
          "exception": false,
          "start_time": "2021-11-18T22:21:54.964323",
          "status": "completed"
        },
        "tags": [],
        "id": "CLXN9QMiAYOH",
        "outputId": "eaaa1589-eb36-47fd-c305-dcfae33470c2"
      },
      "source": [
        "print(f'Συνολικά, το hyperparameter-optimization διήρκησε {str(datetime.timedelta(seconds=round(end-start)))}, με το καλύτερο trial να πετυχαίνει accuracy {round(study.best_value, 5)}, με υπερπαραμέτρους: ')\n",
        "for i in study.best_params:\n",
        "    print(f\"\\t{i}: {(study.best_params)[i]}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Συνολικά, το hyperparameter-optimization διήρκησε 1:15:19, με το καλύτερο trial να πετυχαίνει accuracy 0.96267, με υπερπαραμέτρους: \n",
            "\tVariance_threshold: 0.5\n",
            "\tPCA_components: 9\n",
            "\tactivation: tanh\n",
            "\tAlpha: 0.01582798390741313\n",
            "\tHidden_layers_size: (12, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "papermill": {
          "duration": 93.136534,
          "end_time": "2021-11-18T22:23:28.255384",
          "exception": false,
          "start_time": "2021-11-18T22:21:55.118850",
          "status": "completed"
        },
        "tags": [],
        "id": "24aba5d5",
        "execution": {
          "iopub.status.busy": "2021-12-01T12:30:03.925272Z",
          "iopub.execute_input": "2021-12-01T12:30:03.925522Z",
          "iopub.status.idle": "2021-12-01T12:31:04.713549Z",
          "shell.execute_reply.started": "2021-12-01T12:30:03.925493Z",
          "shell.execute_reply": "2021-12-01T12:31:04.712407Z"
        },
        "trusted": true,
        "outputId": "7ca87473-4215-4b00-a305-7bb336b5005e"
      },
      "source": [
        "final_estimator = Pipeline(steps=[('sampler', SMOTE(n_jobs=-1)),\n",
        "                           ('selector', VarianceThreshold(threshold = 0.5)),\n",
        "                           ('scaler', RobustScaler()),\n",
        "                           ('pca', PCA(n_components=9)),\n",
        "                           ('MLP', MLP(solver=\"adam\", activation='tanh', alpha=0.0012943144637461584,  hidden_layer_sizes=(12, 6)))],\n",
        "                        memory = 'tmp')\n",
        "\n",
        "\n",
        "start_train_MLP = time.time()\n",
        "final_estimator.fit(x_train, y_train)\n",
        "end_train_MLP = time.time()\n",
        "\n",
        "start_test_MLP = time.time()\n",
        "prediction_MLP = final_estimator.predict(x_test)\n",
        "end_test_MLP = time.time()\n",
        "\n",
        "print(f\"Συνολικά, το τελικό μοντέλο χρειάστηκε {round(end_train_MLP-start_train_MLP, 2)} sec για το fitting στο training set, και {round(end_test_MLP-start_test_MLP, 2)} sec για το predict στο test set.\")\n",
        "print(f\"\\n\\n Αναλυτικά, τα αποτελέσματα ήταν:\\n\")\n",
        "print(sklearn.metrics.classification_report(y_test, prediction_MLP))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Συνολικά, το τελικό μοντέλο χρειάστηκε 59.99 sec για το fitting στο training set, και 0.05 sec για το predict στο test set.\n\n\n Αναλυτικά, τα αποτελέσματα ήταν:\n\n              precision    recall  f1-score   support\n\n      GALAXY       0.98      0.96      0.97     15318\n         QSO       0.91      0.94      0.92      3177\n        STAR       0.95      0.97      0.96     11505\n\n    accuracy                           0.96     30000\n   macro avg       0.95      0.96      0.95     30000\nweighted avg       0.96      0.96      0.96     30000\n\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bREZ4DyW1NgS"
      },
      "source": [
        "Βλέπουμε ότι τελικά φτάσαμε να έχουμε αρκετά καλή απόδοση (>0.90) σε όλες τις κλάσεις, για όλες τις συχνές μετρικές. Η διαδικασία επιλογής των βημάτων του Pipe εξηγήθηκαν παραπάνω. Όσον αφορά την επιλογή των arguments στην βελτιστοποίηση με την Optuna, μετά από λίγα δοκιμαστικά runs (αφού αξιολογήθηκε ο χρόνος που παίρνει το κάθε trial συγκριτικά με την βελτίωση της μετρικής), βάλαμε το n_trials ίσο με 100. To optimization τελικά κράτησε λίγο παραπάνω από μία ώρα, και έδωσε αρκετά καλά αποτελέσματα.\n",
        "\n",
        "Όσο για τα υπόλοιπα arguments, στο documentation αναφέρεται ότι ο default sampler δίνει καλά αποτελέσματα στα περισσότερα classification προβλήματα (χωρίς μεγάλο υπολογιστικό φόρτο). Συγκεκριμένα, ο default sampler της Optuna είναι Tree-Structured Parzen Estimator, ο οποίος διαδοχικά κατασκευάζει κάθε φορά ένα σετ υπερπαραμέτρων, με βάση τα αποτελέσματα προηγούμενων trials. Όσο για pruner, δεν χρησιμοποιήθηκε κάποιος, αφού κάθε trial έπαιρνε περίπου 40-55 δευτερόλεπτα για να επιστρέψει το αποτέλεσμα της μετρικής."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LHySPiq1avx"
      },
      "source": [
        "#####Βελτιστοποίηση SVM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvEkAXT91qSC"
      },
      "source": [
        "<h2>Βελτιστοποίηση</h2>\n",
        "Για τη βελτιστοποίηση του SVC θα χρησιμοποιήσουμε τη βιβλιοθήκη Optuna. Θα δημιουργήσουμε ένα Pipeline με τα components που χρησιμοποιήσαμε και στα Multi-Layer Perceptrons και με το Study.optimize της Optuna θα βρούμε τις καλύτερες παραμέτρους για το Pipeline."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-28T09:33:48.401166Z",
          "iopub.status.busy": "2021-11-28T09:33:48.400417Z",
          "iopub.status.idle": "2021-11-28T10:31:05.354456Z",
          "shell.execute_reply": "2021-11-28T10:31:05.355170Z",
          "shell.execute_reply.started": "2021-11-27T16:26:05.802913Z"
        },
        "papermill": {
          "duration": 3437.017559,
          "end_time": "2021-11-28T10:31:05.355367",
          "exception": false,
          "start_time": "2021-11-28T09:33:48.337808",
          "status": "completed"
        },
        "tags": [],
        "id": "g_fbLxhCAc6n",
        "outputId": "885b3565-938e-4121-806b-f50545ea0d31"
      },
      "source": [
        "import numpy as np\n",
        "import time\n",
        "from sklearn.svm import LinearSVC\n",
        "import optuna\n",
        "from optuna.study import create_study\n",
        "from imblearn.pipeline import Pipeline\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
        "\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "optuna.logging.set_verbosity(optuna.logging.ERROR)\n",
        "\n",
        "def objective(trial):\n",
        "    pipe = Pipeline(steps=[('sampler', SMOTE(n_jobs=-1)),\n",
        "                           ('selector', VarianceThreshold(threshold = trial.suggest_float(\"selector__threshold\", low=0.5, high=2.0, step=0.2))),\n",
        "                           ('scaler', RobustScaler()),\n",
        "                           ('pca', PCA(n_components=trial.suggest_int(\"pca__n_components\", 1, 10))),\n",
        "                           ('svm', LinearSVC(C = trial.suggest_float(\"svm__C\", low=0.1, high=2.0, step = 0.2)))],\n",
        "                    memory = 'tmp')\n",
        "    scores = cross_val_score(pipe, x_train, y_train, scoring=\"accuracy\", cv=5, n_jobs=-1, error_score=0.0)\n",
        "    return (sum(scores)/len(scores))\n",
        "                           \n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "start = time.time()\n",
        "study.optimize(objective, n_jobs=-1, n_trials=80)\n",
        "end = time.time()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:226: UserWarning: Persisting input arguments took 0.54s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.74s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.71s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.67s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.64s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.72s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.70s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.67s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.64s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.65s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.63s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.70s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.75s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:226: UserWarning: Persisting input arguments took 0.50s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.71s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.68s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.73s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:226: UserWarning: Persisting input arguments took 0.54s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.73s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.70s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.66s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.64s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.72s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.69s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.71s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.67s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.72s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.67s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.90s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.77s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.73s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.72s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.69s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:226: UserWarning: Persisting input arguments took 0.57s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.74s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.71s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.71s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.71s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.66s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.70s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.65s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.68s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.74s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.70s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.69s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.74s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.76s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.70s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.79s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:226: UserWarning: Persisting input arguments took 0.54s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.74s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.70s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.70s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.77s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.70s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.70s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.69s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.66s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.66s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.74s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.69s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.73s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.70s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.68s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.69s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.69s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.72s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.69s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.66s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.69s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.68s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.70s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.70s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.73s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.70s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.77s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.70s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.67s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.67s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.89s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.65s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.69s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.65s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.69s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.71s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.66s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.65s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.66s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.70s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.66s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.66s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.67s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.67s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.67s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.68s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.66s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.66s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.72s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.67s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.64s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.65s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.66s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.68s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.74s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.68s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.69s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.67s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.70s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.67s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.69s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.64s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.66s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.66s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.65s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.70s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.66s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.66s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.78s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.67s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.65s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.68s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.70s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.93s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.69s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.67s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.72s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.70s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.71s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.70s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.69s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.69s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.69s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.69s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.67s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.66s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 1.06s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.66s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.68s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.69s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.67s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.67s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.68s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.67s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.68s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.68s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.67s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.78s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.68s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.66s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.67s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.68s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.66s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.68s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.72s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.72s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.67s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.83s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.69s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.67s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/imblearn/pipeline.py:217: UserWarning: Persisting input arguments took 0.78s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  **fit_params_steps[name],\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-28T10:31:05.494873Z",
          "iopub.status.busy": "2021-11-28T10:31:05.493856Z",
          "iopub.status.idle": "2021-11-28T10:31:05.500953Z",
          "shell.execute_reply": "2021-11-28T10:31:05.501799Z",
          "shell.execute_reply.started": "2021-11-27T17:34:26.836633Z"
        },
        "papermill": {
          "duration": 0.079524,
          "end_time": "2021-11-28T10:31:05.502020",
          "exception": false,
          "start_time": "2021-11-28T10:31:05.422496",
          "status": "completed"
        },
        "tags": [],
        "id": "WRvBY5fEAhCj",
        "outputId": "a6038a74-6526-40a3-befb-f7933d85c2ab"
      },
      "source": [
        "print(f'Συνολικά, το hyperparameter-optimization διήρκησε {str(datetime.timedelta(seconds=round(end-start)))}, με το καλύτερο trial να πετυχαίνει accuracy {round(study.best_value, 5)}, με υπερπαραμέτρους: ')\n",
        "for i in study.best_params:\n",
        "    print(f\"\\t{i}: {(study.best_params)[i]}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Συνολικά, το hyperparameter-optimization διήρκησε 0:57:16, με το καλύτερο trial να πετυχαίνει accuracy 0.82956, με υπερπαραμέτρους: \n",
            "\tselector__threshold: 1.5\n",
            "\tpca__n_components: 7\n",
            "\tsvm__C: 1.7000000000000002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "papermill": {
          "duration": 52.933722,
          "end_time": "2021-11-28T10:31:58.503038",
          "exception": false,
          "start_time": "2021-11-28T10:31:05.569316",
          "status": "completed"
        },
        "tags": [],
        "id": "bb2bdcc4",
        "execution": {
          "iopub.status.busy": "2021-12-01T12:31:04.715072Z",
          "iopub.execute_input": "2021-12-01T12:31:04.715294Z",
          "iopub.status.idle": "2021-12-01T12:32:03.501432Z",
          "shell.execute_reply.started": "2021-12-01T12:31:04.715267Z",
          "shell.execute_reply": "2021-12-01T12:32:03.500740Z"
        },
        "trusted": true,
        "outputId": "6c9b8dbb-9fd5-4c33-e9e2-9ca22b634ceb"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "final_estimator = Pipeline(steps=[('sampler', SMOTE(n_jobs=-1)),\n",
        "                           ('selector', VarianceThreshold(threshold = 1.5)),\n",
        "                           ('scaler', RobustScaler()),\n",
        "                           ('pca', PCA(n_components = 7)),\n",
        "                           ('svm', LinearSVC(C= 1.7000000000000002))],\n",
        "                           memory = 'tmp')\n",
        "\n",
        "start_train_SVC = time.time()\n",
        "final_estimator.fit(x_train, y_train)\n",
        "end_train_SVC = time.time()\n",
        "\n",
        "start_test_SVC = time.time()\n",
        "prediction_SVC = final_estimator.predict(x_test)\n",
        "end_test_SVC = time.time()\n",
        "\n",
        "print(f\"Συνολικά, το τελικό μοντέλο χρειάστηκε {round(end_train_SVC-start_train_SVC, 2)} sec για το fitting στο training set, και {round(end_test_SVC-start_test_SVC, 2)} sec για το predict στο test set.\")\n",
        "print(f\"\\n\\n Αναλυτικά, τα αποτελέσματα ήταν:\\n\")\n",
        "print(classification_report(y_test, prediction_SVC))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Συνολικά, το τελικό μοντέλο χρειάστηκε 57.72 sec για το fitting στο training set, και 0.0 sec για το predict στο test set.\n\n\n Αναλυτικά, τα αποτελέσματα ήταν:\n\n              precision    recall  f1-score   support\n\n      GALAXY       0.91      0.88      0.90     15318\n         QSO       0.52      0.85      0.64      3177\n        STAR       0.86      0.74      0.79     11505\n\n    accuracy                           0.82     30000\n   macro avg       0.76      0.82      0.78     30000\nweighted avg       0.85      0.82      0.83     30000\n\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVS-SNzY2KI3"
      },
      "source": [
        "#Σύγκριση αποτελεσμάτων"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MH2eircmzwNw",
        "execution": {
          "iopub.status.busy": "2021-12-01T12:32:03.502550Z",
          "iopub.execute_input": "2021-12-01T12:32:03.502955Z",
          "iopub.status.idle": "2021-12-01T12:32:03.766169Z",
          "shell.execute_reply.started": "2021-12-01T12:32:03.502925Z",
          "shell.execute_reply": "2021-12-01T12:32:03.765478Z"
        },
        "trusted": true,
        "outputId": "09026939-0b10-411e-93ff-d754415cf7d9"
      },
      "source": [
        "# Look at index 4 and 6, which demonstrate overlapping cases.\n",
        "x1 = ['MLP', 'Linear_SVC']\n",
        "y2 = [accuracy_score(prediction_MLP, y_test), accuracy_score(prediction_SVC, y_test)]\n",
        "\n",
        "from matplotlib.pyplot import figure\n",
        "\n",
        "figure(figsize=(8, 6), dpi=80)\n",
        "plt.bar(x1, y2, label=\"Accuracies\", color='b')\n",
        "#plt.bar(x1, y2, label = 'Accuracy of out-of-the-box', color='r')\n",
        "plt.bar(x1, [b-a for a, b in zip([y1[0], y1[2]], y2)], label= 'Change of accuracy compared to out-of-the-box', color='r')\n",
        "plt.plot()\n",
        "\n",
        "plt.xlabel(\"Classifier\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Accuracy comparison\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 640x480 with 1 Axes>",
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAxTXydB25Ew"
      },
      "source": [
        "Παρατηρούμε ότι με τον MLP επιτεύχθηκε εμφανώς καλύτερο accuracy από ότι με τη χρήση Linear_SVC. Η διαφόρα και των δύο ταξινομητών έπειτα από τη βελτιστοποίηση (κόκκινο) είναι μεγάλη και κυμαίνεται στα ίδια επίπεδα"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdgEeK8NzwNw",
        "execution": {
          "iopub.status.busy": "2021-12-01T12:32:03.767527Z",
          "iopub.execute_input": "2021-12-01T12:32:03.767775Z",
          "iopub.status.idle": "2021-12-01T12:32:04.336219Z",
          "shell.execute_reply.started": "2021-12-01T12:32:03.767746Z",
          "shell.execute_reply": "2021-12-01T12:32:04.335150Z"
        },
        "trusted": true,
        "outputId": "f44a892d-ed12-42b6-e75c-c8c7b8115ac1"
      },
      "source": [
        "x1 = ['MLP', 'Linear_SVC']\n",
        "y2 = [f1_score(prediction_MLP, y_test, average='macro'), f1_score(prediction_SVC, y_test, average = 'macro')]\n",
        "\n",
        "# Colors: https://matplotlib.org/api/colors_api.html\n",
        "from matplotlib.pyplot import figure\n",
        "\n",
        "figure(figsize=(8, 6), dpi=80)\n",
        "plt.bar(x1, y2, label=\"f1-scores\", color='b')\n",
        "#plt.bar(x1, y2, label = 'Accuracy of out-of-the-box', color='r')\n",
        "plt.bar(x1, [b-a for a, b in zip([y1[1], y1[3]], y2)], label= 'Change of accuracy compared to out-of-the-box', color='r')\n",
        "\n",
        "plt.plot()\n",
        "\n",
        "plt.xlabel(\"Classifier\")\n",
        "plt.ylabel(\"F1\")\n",
        "plt.title(\"F1 comparison\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 640x480 with 1 Axes>",
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A73Zfl673ViR"
      },
      "source": [
        "Μεγάλες είναι οι βελτιώσεις και στο f1-score, ειδικά στην περίπτωση του Linear_SVC, ο οποίος είχε παρουσιάσει πολύ μικρό f1-score στην out-of-the-box υλοποίηση του. Παρόλ'αυτά ο MLP είναι καλύτερος από τον Linear_SVC και όσον αφορά το f1-score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGzWkmEOzwNw",
        "execution": {
          "iopub.status.busy": "2021-12-01T12:32:04.338289Z",
          "iopub.execute_input": "2021-12-01T12:32:04.338919Z",
          "iopub.status.idle": "2021-12-01T12:32:04.767855Z",
          "shell.execute_reply.started": "2021-12-01T12:32:04.338881Z",
          "shell.execute_reply": "2021-12-01T12:32:04.766906Z"
        },
        "trusted": true,
        "outputId": "41c0a992-7d9f-4da3-810c-bf0dd1750228"
      },
      "source": [
        "markdown = \"\"\"Classifiers  | Accuracy | f1-score | Train Time | Test Time\n",
        "------------- | ------------- | ------------|---------------|-------------\"\"\"\n",
        "classifierss = ['MLP', 'LinearSVC']\n",
        "predicts = [prediction_MLP, prediction_SVC]\n",
        "train_times = [end_train_MLP - start_train_MLP, end_train_SVC - start_train_SVC]\n",
        "test_times = [end_test_MLP - start_test_MLP, end_test_SVC - start_test_SVC]\n",
        "y1= []\n",
        "\n",
        "for i in range(2):\n",
        "    acc = accuracy_score(predicts[i], y_test)\n",
        "    y1.append(acc)\n",
        "    f1 = f1_score(predicts[i], y_test, average = 'macro')\n",
        "    y1.append(f1)\n",
        "    markdown += \"\"\"\n",
        "     {} | {} | {} | {} | {}\"\"\".format(classifierss[i], round(acc,3), round(f1,3), round(train_times[i],4), round(test_times[i],5))\n",
        "printmd(markdown)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.Markdown object>",
            "text/markdown": "Classifiers  | Accuracy | f1-score | Train Time | Test Time\n------------- | ------------- | ------------|---------------|-------------\n     MLP | 0.963 | 0.953 | 59.9946 | 0.05051\n     LinearSVC | 0.824 | 0.778 | 57.7153 | 0.0049"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2z7e1go3yRl"
      },
      "source": [
        "Στον παραπάνω πίνακα φαίνεται ότι αν και όπως είδαμε στα bar-plots, ο MLP παρουσιάζει καλύτερες επιδόσεις από τον LinearSVC, το predict time του MLP είναι αρκετά μεγαλύτερα. Επίσης σε άλλες εκτελέσεις προέκυπτε για τον MLP και μεγαύτερο fit time.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFZiXatQ_kEr"
      },
      "source": [
        "#Συμπεράσματα"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llpWz46A_1Mk"
      },
      "source": [
        "Όπως φάνηκε παραπάνω ο MLP είχε καλύτερες επιδόσεις από τον LinearSVC, τόσο πριν όσο και μετά από την βελτιστοποίηση. Ίσως προέκυπταν καλύτερα αποτελέσματα αν γινόταν χρήση ενός άλλου kernel για το SVM, ωστόσο οι χρόνοι για την εύρεση βέλτιστων παραμέτρων ήταν αποτρεπτικοί. Η επίδοση του, λοιπόν, είναι πιθανό να μην είναι τόσο καλή, επειδή μπορεί τα δεδομένα να μην είναι εντελώς γραμμικά διαχωρίσιμα. Σαν ταξινομήτη θα επιλέγαμε λοιπόν σε αυτό το σύνολο δεδομένων τον Multi Layer Perceptron. Αυτό το συμπέρασμα, είναι σε συμφωνία με την τάση της πτώσης της δημοφιλίας των SVM. "
      ]
    }
  ]
}